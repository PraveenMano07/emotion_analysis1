{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JbLJ_0yv3yhR"
      },
      "outputs": [],
      "source": [
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Must be the first Streamlit command!\n",
        "st.set_page_config(page_title=\"Emotion Detector\", layout=\"wide\")\n",
        "\n",
        "# 1. Load dataset\n",
        "def load_dataset(file_path):\n",
        "    texts = []\n",
        "    labels = []\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        for line in file:\n",
        "            if ';' in line:\n",
        "                parts = line.strip().split(';')\n",
        "                if len(parts) == 2:\n",
        "                    texts.append(parts[0])\n",
        "                    labels.append(parts[1])\n",
        "    return pd.DataFrame({'text': texts, 'label': labels})\n",
        "\n",
        "# 2. Train model (cache with new decorator)\n",
        "@st.cache_data(show_spinner=True)\n",
        "def train_model():\n",
        "    df = load_dataset(\"train.txt\")\n",
        "    X = df['text']\n",
        "    y = df['label']\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
        "    X_train_vec = vectorizer.fit_transform(X_train)\n",
        "    X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "    model = LogisticRegression(max_iter=1000)\n",
        "    model.fit(X_train_vec, y_train)\n",
        "\n",
        "    y_pred = model.predict(X_test_vec)\n",
        "\n",
        "    return df, vectorizer, model, X_test, y_test, y_pred\n",
        "\n",
        "# 3. Main App\n",
        "st.title(\"Emotion Detection from Text\")\n",
        "\n",
        "df, vectorizer, model, X_test, y_test, y_pred = train_model()\n",
        "\n",
        "# Sidebar Input\n",
        "user_input = st.text_input(\"Enter a sentence to analyze emotion:\")\n",
        "\n",
        "if user_input:\n",
        "    vec = vectorizer.transform([user_input])\n",
        "    pred = model.predict(vec)[0]\n",
        "    pred_proba = model.predict_proba(vec)[0]\n",
        "    prob = pred_proba.max()\n",
        "    st.subheader(\"Prediction Result\")\n",
        "    st.write(f\"**Predicted Emotion:** {pred}\")\n",
        "    st.write(f\"**Confidence:** {prob:.2f}\")\n",
        "\n",
        "    # Bar plot of prediction probabilities\n",
        "    classes = model.classes_\n",
        "    fig1, ax1 = plt.subplots(figsize=(8,4))\n",
        "    sns.barplot(x=classes, y=pred_proba, ax=ax1, palette='viridis')\n",
        "    ax1.set_ylabel(\"Probability\")\n",
        "    ax1.set_xlabel(\"Emotion Class\")\n",
        "    ax1.set_title(\"Prediction Confidence per Emotion Class\")\n",
        "    plt.xticks(rotation=45)\n",
        "    st.pyplot(fig1)\n",
        "\n",
        "# Data Visualization\n",
        "st.subheader(\"Emotion Distribution in Dataset\")\n",
        "fig2, ax2 = plt.subplots(figsize=(10, 5))\n",
        "sns.countplot(data=df, x='label', order=df['label'].value_counts().index, palette='viridis', ax=ax2)\n",
        "plt.xticks(rotation=45)\n",
        "st.pyplot(fig2)\n",
        "\n",
        "\n",
        "# Confusion Matrix\n",
        "st.subheader(\"Confusion Matrix\")\n",
        "labels_sorted = sorted(model.classes_)\n",
        "cm = confusion_matrix(y_test, y_pred, labels=labels_sorted)\n",
        "fig4, ax4 = plt.subplots(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', xticklabels=labels_sorted, yticklabels=labels_sorted, cmap='Blues', ax=ax4)\n",
        "ax4.set_xlabel(\"Predicted\")\n",
        "ax4.set_ylabel(\"Actual\")\n",
        "st.pyplot(fig4)\n",
        "\n",
        "# Metrics\n",
        "st.subheader(\"Evaluation Metrics\")\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "st.write(f\"**Accuracy:**  {accuracy:.4f}\")\n",
        "st.write(f\"**Precision:** {precision:.4f}\")\n",
        "st.write(f\"**Recall:**    {recall:.4f}\")\n",
        "st.write(f\"**F1 Score:**  {f1:.4f}\")"
      ]
    }
  ]
}